{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain-google-genai \n",
    "# pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "google_gemini_api=os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anuragsingh/Documents/GitHub/Mr-analyzer/analyzerenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721506661.682962  298750 config.cc:230] gRPC experiments enabled: call_status_override_on_cancellation, event_engine_dns, event_engine_listener, http2_stats_fix, monitoring_experiment, pick_first_new, trace_record_callops, work_serializer_clears_time_cache\n",
      "I0000 00:00:1721506661.689778  298750 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1721506661.690683  298750 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm_model=ChatGoogleGenerativeAI(model=\"gemini-pro\",google_api_key=google_gemini_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE=\"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz of {number} multiple choice questions for the disease {disease_name} for public in {tone} tone for the awareness. \n",
    "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. \\\n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"disease_name\", \"tone\", \"response_json\"],\n",
    "    template=TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anuragsingh/Documents/GitHub/Mr-analyzer/analyzerenv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "quiz_chain=LLMChain(llm=llm_model, prompt=quiz_generation_prompt, output_key=\"quiz\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2=\"\"\"\n",
    "You are an medical expert and health advocates or public health advocates. Given a Multiple Choice Quiz for {disease_name} disease.\\\n",
    "You need to evaluate the quality of the question and give a complete analysis of the quiz. Only use at max 50 words for quality analysis. \n",
    "if the quiz is not at per with the quality and awreness and helpfull related to the public,\\\n",
    "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the public awareness and health\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an medical expert and health advocates or public health advocates of the above quiz:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt=PromptTemplate(input_variables=[\"disease_name\", \"quiz\"], template=TEMPLATE2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain=LLMChain(llm=llm_model, prompt=quiz_evaluation_prompt, output_key=\"review\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_evaluate_chain=SequentialChain(\n",
    "    chains=[quiz_chain, review_chain], \n",
    "    input_variables=[\"text\", \"number\", \"disease_name\", \"tone\", \"response_json\"],\n",
    "    output_variables=[\"quiz\", \"review\"], \n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading the data for generating the MCQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(RESPONSE_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text:0    Jaundice is a medical condition characterized ...\n",
      "Name: text, dtype: object\n",
      "You are an expert MCQ maker. Given the above text, it is your job to create a quiz of 0    5\n",
      "Name: number, dtype: int64 multiple choice questions for the disease 0    Jaundice\n",
      "Name: disease_name, dtype: object for public in 0    good\n",
      "Name: tone, dtype: object tone for the awareness. \n",
      "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
      "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. Ensure to make 0    5\n",
      "Name: number, dtype: int64 MCQs\n",
      "### RESPONSE_JSON\n",
      "{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an medical expert and health advocates or public health advocates. Given a Multiple Choice Quiz for 0    Jaundice\n",
      "Name: disease_name, dtype: object disease.You need to evaluate the quality of the question and give a complete analysis of the quiz. Only use at max 50 words for quality analysis. \n",
      "if the quiz is not at per with the quality and awreness and helpfull related to the public,update the quiz questions which needs to be changed and change the tone such that it perfectly fits the public awareness and health\n",
      "Quiz_MCQs:\n",
      "### RESPONSE_JSON\n",
      "{\"1\": {\"mcq\": \"What is the medical condition characterized by yellowing of the skin and whites of the eyes?\", \"options\": {\"a\": \"Jaundice\", \"b\": \"Cirrhosis\", \"c\": \"Hepatitis\", \"d\": \"Hemochromatosis\"}, \"correct\": \"a\"}, \"2\": {\"mcq\": \"Which of the following is a symptom of jaundice?\", \"options\": {\"a\": \"Yellowing of the skin\", \"b\": \"Dark urine\", \"c\": \"Pale stools\", \"d\": \"All of the above\"}, \"correct\": \"d\"}, \"3\": {\"mcq\": \"What is the most common cause of jaundice in newborns?\", \"options\": {\"a\": \"Breast milk jaundice\", \"b\": \"Liver disease\", \"c\": \"Gallstones\", \"d\": \"Pancreatitis\"}, \"correct\": \"a\"}, \"4\": {\"mcq\": \"Which of the following tests is used to diagnose jaundice?\", \"options\": {\"a\": \"Blood test\", \"b\": \"Liver biopsy\", \"c\": \"Ultrasound\", \"d\": \"All of the above\"}, \"correct\": \"d\"}, \"5\": {\"mcq\": \"What is the treatment for jaundice?\", \"options\": {\"a\": \"Medication\", \"b\": \"Surgery\", \"c\": \"Lifestyle changes\", \"d\": \"A combination of treatments\"}, \"correct\": \"d\"}}\n",
      "\n",
      "Check from an medical expert and health advocates or public health advocates of the above quiz:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response=generate_evaluate_chain(\n",
    "    {\n",
    "        \"text\":new_df.text,\n",
    "        \"number\":new_df.number,\n",
    "        \"disease_name\":new_df.disease_name,\n",
    "        \"tone\":new_df.tone,\n",
    "        \"response_json\":json.dumps(RESPONSE_JSON)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 0    Jaundice is a medical condition characterized ...\n",
       " Name: text, dtype: object,\n",
       " 'number': 0    5\n",
       " Name: number, dtype: int64,\n",
       " 'disease_name': 0    Jaundice\n",
       " Name: disease_name, dtype: object,\n",
       " 'tone': 0    good\n",
       " Name: tone, dtype: object,\n",
       " 'response_json': '{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}',\n",
       " 'quiz': '### RESPONSE_JSON\\n{\"1\": {\"mcq\": \"What is the medical condition characterized by yellowing of the skin and whites of the eyes?\", \"options\": {\"a\": \"Jaundice\", \"b\": \"Cirrhosis\", \"c\": \"Hepatitis\", \"d\": \"Hemochromatosis\"}, \"correct\": \"a\"}, \"2\": {\"mcq\": \"Which of the following is a symptom of jaundice?\", \"options\": {\"a\": \"Yellowing of the skin\", \"b\": \"Dark urine\", \"c\": \"Pale stools\", \"d\": \"All of the above\"}, \"correct\": \"d\"}, \"3\": {\"mcq\": \"What is the most common cause of jaundice in newborns?\", \"options\": {\"a\": \"Breast milk jaundice\", \"b\": \"Liver disease\", \"c\": \"Gallstones\", \"d\": \"Pancreatitis\"}, \"correct\": \"a\"}, \"4\": {\"mcq\": \"Which of the following tests is used to diagnose jaundice?\", \"options\": {\"a\": \"Blood test\", \"b\": \"Liver biopsy\", \"c\": \"Ultrasound\", \"d\": \"All of the above\"}, \"correct\": \"d\"}, \"5\": {\"mcq\": \"What is the treatment for jaundice?\", \"options\": {\"a\": \"Medication\", \"b\": \"Surgery\", \"c\": \"Lifestyle changes\", \"d\": \"A combination of treatments\"}, \"correct\": \"d\"}}',\n",
       " 'review': '**Quality Analysis:**\\n\\nThe quiz is concise and covers basic information about jaundice. However, it lacks depth and some questions are not worded clearly.\\n\\n**Updated Quiz Questions:**\\n\\n1. What is the medical condition characterized by yellowing of the skin and eyes?\\n   - (a) Jaundice\\n   - (b) Liver failure\\n   - (c) Hepatitis\\n   - (d) Gallstones\\n   **Correct Answer:** (a) Jaundice\\n\\n2. Which of the following is NOT a symptom of jaundice?\\n   - (a) Yellowing of the skin\\n   - (b) Dark urine\\n   - (c) Pale stools\\n   - (d) Fatigue\\n   **Correct Answer:** (d) Fatigue\\n\\n3. What is the most common cause of jaundice in infants?\\n   - (a) Breast milk jaundice\\n   - (b) Liver disease\\n   - (c) Gallstones\\n   - (d) Pancreatitis\\n   **Correct Answer:** (a) Breast milk jaundice\\n\\n4. Which of the following tests can be used to diagnose jaundice?\\n   - (a) Blood test\\n   - (b) Liver biopsy\\n   - (c) Ultrasound\\n   - (d) All of the above\\n   **Correct Answer:** (d) All of the above\\n\\n5. What is the treatment for jaundice?\\n   - (a) Medication\\n   - (b) Surgery\\n   - (c) Lifestyle changes (e.g., avoiding alcohol)\\n   - (d) A combination of treatments\\n   **Correct Answer:** (d) A combination of treatments\\n\\n**Changes in Tone:**\\n\\nThe updated questions are more specific, concise, and informative. They avoid medical jargon and are written in a clear and easy-to-understand manner for the general public.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_quiz_df=pd.DataFrame([response])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: What is the medical condition characterized by yellowing of the skin and whites of the eyes?\n",
      "  a: Jaundice\n",
      "  b: Cirrhosis\n",
      "  c: Hepatitis\n",
      "  d: Hemochromatosis\n",
      "Correct Answer: a\n",
      "\n",
      "Question 2: Which of the following is a symptom of jaundice?\n",
      "  a: Yellowing of the skin\n",
      "  b: Dark urine\n",
      "  c: Pale stools\n",
      "  d: All of the above\n",
      "Correct Answer: d\n",
      "\n",
      "Question 3: What is the most common cause of jaundice in newborns?\n",
      "  a: Breast milk jaundice\n",
      "  b: Liver disease\n",
      "  c: Gallstones\n",
      "  d: Pancreatitis\n",
      "Correct Answer: a\n",
      "\n",
      "Question 4: Which of the following tests is used to diagnose jaundice?\n",
      "  a: Blood test\n",
      "  b: Liver biopsy\n",
      "  c: Ultrasound\n",
      "  d: All of the above\n",
      "Correct Answer: d\n",
      "\n",
      "Question 5: What is the treatment for jaundice?\n",
      "  a: Medication\n",
      "  b: Surgery\n",
      "  c: Lifestyle changes\n",
      "  d: A combination of treatments\n",
      "Correct Answer: d\n",
      "\n"
     ]
    }
   ],
   "source": [
    "quiz_json = new_quiz_df.loc[0, 'quiz'].split('### RESPONSE_JSON\\n')[1]\n",
    "quiz_data = json.loads(quiz_json)\n",
    "\n",
    "# Display the quiz questions\n",
    "for key, value in quiz_data.items():\n",
    "    print(f\"Question {key}: {value['mcq']}\")\n",
    "    for option_key, option_value in value['options'].items():\n",
    "        print(f\"  {option_key}: {option_value}\")\n",
    "    print(f\"Correct Answer: {value['correct']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_list = []\n",
    "for key, value in quiz_data.items():\n",
    "    question = value['mcq']\n",
    "    options = value['options']\n",
    "    correct_ans = value['correct']\n",
    "    row = {\n",
    "        'question': question,\n",
    "        'optiona': options.get('a', ''),\n",
    "        'optionb': options.get('b', ''),\n",
    "        'optionc': options.get('c', ''),\n",
    "        'optiond': options.get('d', ''),\n",
    "        'correctans': correct_ans\n",
    "    }\n",
    "    quiz_list.append(row)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_quiz = pd.DataFrame(quiz_list)\n",
    "\n",
    "# Save to CSV\n",
    "df_quiz.to_csv('quiz_questions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analyzerenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
